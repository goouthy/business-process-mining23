{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b6414ff",
   "metadata": {},
   "source": [
    "# Homework 4: Predictive Process Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb4452",
   "metadata": {},
   "source": [
    "### Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6e0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_org = pd.read_csv('BPI_Challenge_2012_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3e701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_org.sort_values(['case_id', 'Start_Time', 'End_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "855178ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'])\n",
    "df['End_Time'] = pd.to_datetime(df['End_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92ef3842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['remtime'] = (df.groupby('case_id')['End_Time'].transform('max') - df.groupby('case_id')['Start_Time'].transform('min')) // pd.Timedelta('1s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac02f967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>AMOUNT_REQ</th>\n",
       "      <th>resource</th>\n",
       "      <th>activity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>REG_DATE</th>\n",
       "      <th>remtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8272</th>\n",
       "      <td>195455</td>\n",
       "      <td>5000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-12-24 11:18:27.336</td>\n",
       "      <td>2011-12-24 11:18:27.336</td>\n",
       "      <td>2011-12-24T11:18:27.336</td>\n",
       "      <td>861917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8273</th>\n",
       "      <td>195455</td>\n",
       "      <td>5000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-12-24 11:18:29.367</td>\n",
       "      <td>2011-12-24 11:18:29.367</td>\n",
       "      <td>2011-12-24T11:18:27.336</td>\n",
       "      <td>861917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8274</th>\n",
       "      <td>195455</td>\n",
       "      <td>5000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-12-24 11:19:07.492</td>\n",
       "      <td>2011-12-24 11:19:07.492</td>\n",
       "      <td>2011-12-24T11:18:27.336</td>\n",
       "      <td>861917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8275</th>\n",
       "      <td>195455</td>\n",
       "      <td>5000</td>\n",
       "      <td>10913.0</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-12-24 13:52:01.453</td>\n",
       "      <td>2011-12-24 13:52:12.990</td>\n",
       "      <td>2011-12-24T11:18:27.336</td>\n",
       "      <td>861917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>195455</td>\n",
       "      <td>5000</td>\n",
       "      <td>10913.0</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-12-24 15:04:35.228</td>\n",
       "      <td>2011-12-24 15:13:54.172</td>\n",
       "      <td>2011-12-24T11:18:27.336</td>\n",
       "      <td>861917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_id  AMOUNT_REQ  resource                activity  \\\n",
       "8272   195455        5000     112.0             A_SUBMITTED   \n",
       "8273   195455        5000     112.0       A_PARTLYSUBMITTED   \n",
       "8274   195455        5000     112.0           A_PREACCEPTED   \n",
       "8275   195455        5000   10913.0  W_Completeren aanvraag   \n",
       "8276   195455        5000   10913.0  W_Completeren aanvraag   \n",
       "\n",
       "                  Start_Time                End_Time                 REG_DATE  \\\n",
       "8272 2011-12-24 11:18:27.336 2011-12-24 11:18:27.336  2011-12-24T11:18:27.336   \n",
       "8273 2011-12-24 11:18:29.367 2011-12-24 11:18:29.367  2011-12-24T11:18:27.336   \n",
       "8274 2011-12-24 11:19:07.492 2011-12-24 11:19:07.492  2011-12-24T11:18:27.336   \n",
       "8275 2011-12-24 13:52:01.453 2011-12-24 13:52:12.990  2011-12-24T11:18:27.336   \n",
       "8276 2011-12-24 15:04:35.228 2011-12-24 15:13:54.172  2011-12-24T11:18:27.336   \n",
       "\n",
       "      remtime  \n",
       "8272   861917  \n",
       "8273   861917  \n",
       "8274   861917  \n",
       "8275   861917  \n",
       "8276   861917  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee533eb4",
   "metadata": {},
   "source": [
    "### Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d78ac140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_month'] = df['Start_Time'].dt.month\n",
    "df['end_month'] = df['End_Time'].dt.month\n",
    "\n",
    "df['start_day'] = df['Start_Time'].dt.weekday\n",
    "df['end_day'] = df['End_Time'].dt.weekday\n",
    "\n",
    "df['start_reltime'] = (df['Start_Time'] - pd.to_datetime(df['Start_Time'].dt.date)) // pd.Timedelta('1s')\n",
    "df['end_reltime'] = (df['End_Time'] - pd.to_datetime(df['End_Time'].dt.date)) // pd.Timedelta('1s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "613c560e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>AMOUNT_REQ</th>\n",
       "      <th>resource</th>\n",
       "      <th>activity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>REG_DATE</th>\n",
       "      <th>remtime</th>\n",
       "      <th>start_month</th>\n",
       "      <th>end_month</th>\n",
       "      <th>start_day</th>\n",
       "      <th>end_day</th>\n",
       "      <th>start_reltime</th>\n",
       "      <th>end_reltime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8272</th>\n",
       "      <td>195455</td>\n",
       "      <td>5000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-12-24 11:18:27.336</td>\n",
       "      <td>2011-12-24 11:18:27.336</td>\n",
       "      <td>2011-12-24T11:18:27.336</td>\n",
       "      <td>861917</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>40707</td>\n",
       "      <td>40707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8273</th>\n",
       "      <td>195455</td>\n",
       "      <td>5000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-12-24 11:18:29.367</td>\n",
       "      <td>2011-12-24 11:18:29.367</td>\n",
       "      <td>2011-12-24T11:18:27.336</td>\n",
       "      <td>861917</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>40709</td>\n",
       "      <td>40709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8274</th>\n",
       "      <td>195455</td>\n",
       "      <td>5000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-12-24 11:19:07.492</td>\n",
       "      <td>2011-12-24 11:19:07.492</td>\n",
       "      <td>2011-12-24T11:18:27.336</td>\n",
       "      <td>861917</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>40747</td>\n",
       "      <td>40747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8275</th>\n",
       "      <td>195455</td>\n",
       "      <td>5000</td>\n",
       "      <td>10913.0</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-12-24 13:52:01.453</td>\n",
       "      <td>2011-12-24 13:52:12.990</td>\n",
       "      <td>2011-12-24T11:18:27.336</td>\n",
       "      <td>861917</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>49921</td>\n",
       "      <td>49932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>195455</td>\n",
       "      <td>5000</td>\n",
       "      <td>10913.0</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-12-24 15:04:35.228</td>\n",
       "      <td>2011-12-24 15:13:54.172</td>\n",
       "      <td>2011-12-24T11:18:27.336</td>\n",
       "      <td>861917</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54275</td>\n",
       "      <td>54834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_id  AMOUNT_REQ  resource                activity  \\\n",
       "8272   195455        5000     112.0             A_SUBMITTED   \n",
       "8273   195455        5000     112.0       A_PARTLYSUBMITTED   \n",
       "8274   195455        5000     112.0           A_PREACCEPTED   \n",
       "8275   195455        5000   10913.0  W_Completeren aanvraag   \n",
       "8276   195455        5000   10913.0  W_Completeren aanvraag   \n",
       "\n",
       "                  Start_Time                End_Time                 REG_DATE  \\\n",
       "8272 2011-12-24 11:18:27.336 2011-12-24 11:18:27.336  2011-12-24T11:18:27.336   \n",
       "8273 2011-12-24 11:18:29.367 2011-12-24 11:18:29.367  2011-12-24T11:18:27.336   \n",
       "8274 2011-12-24 11:19:07.492 2011-12-24 11:19:07.492  2011-12-24T11:18:27.336   \n",
       "8275 2011-12-24 13:52:01.453 2011-12-24 13:52:12.990  2011-12-24T11:18:27.336   \n",
       "8276 2011-12-24 15:04:35.228 2011-12-24 15:13:54.172  2011-12-24T11:18:27.336   \n",
       "\n",
       "      remtime  start_month  end_month  start_day  end_day  start_reltime  \\\n",
       "8272   861917           12         12          5        5          40707   \n",
       "8273   861917           12         12          5        5          40709   \n",
       "8274   861917           12         12          5        5          40747   \n",
       "8275   861917           12         12          5        5          49921   \n",
       "8276   861917           12         12          5        5          54275   \n",
       "\n",
       "      end_reltime  \n",
       "8272        40707  \n",
       "8273        40709  \n",
       "8274        40747  \n",
       "8275        49932  \n",
       "8276        54834  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e5613f",
   "metadata": {},
   "source": [
    "### Task 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b440f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_strict(data, timestamp_col, case_id_col, train_ratio, split=\"temporal\"):  \n",
    "    data = data.sort_values([timestamp_col, 'activity'], ascending=True, kind='mergesort')\n",
    "    grouped = data.groupby(case_id_col)\n",
    "    start_timestamps = grouped[timestamp_col].min().reset_index()\n",
    "    start_timestamps = start_timestamps.sort_values(timestamp_col, ascending=True, kind='mergesort')\n",
    "    train_ids = list(start_timestamps[case_id_col])[:int(train_ratio*len(start_timestamps))]\n",
    "    train = data[data[case_id_col].isin(train_ids)].sort_values([timestamp_col, 'activity'], ascending=True, kind='mergesort')\n",
    "    test = data[~data[case_id_col].isin(train_ids)].sort_values([timestamp_col, 'activity'], ascending=True, kind='mergesort')\n",
    "    split_ts = test[timestamp_col].min()\n",
    "    train = train[train[timestamp_col] < split_ts]\n",
    "    return (train, test)\n",
    "\n",
    "train, test = split_data_strict(df, 'End_Time', 'case_id', 0.8, split=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6578a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_case_length_quantile(data, quantile=0.90):\n",
    "    return int(np.ceil(data.groupby('case_id').size().quantile(quantile)))\n",
    "\n",
    "min_prefix_length = 1\n",
    "max_prefix_length = min(40, get_pos_case_length_quantile(df, 0.90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36bd4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abe26fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prefix_data(data, min_length, max_length, gap=1):\n",
    "\n",
    "    data['case_length'] = data.groupby('case_id')['activity'].transform(len)\n",
    "    dt_prefixes = data[data['case_length'] >= min_length].groupby('case_id').head(min_length)\n",
    "    dt_prefixes[\"prefix_nr\"] = 1\n",
    "    dt_prefixes[\"orig_case_id\"] = dt_prefixes['case_id']   \n",
    "    for nr_events in range(min_length+gap, max_length+1, gap):\n",
    "        tmp = data[data['case_length'] >= nr_events].groupby('case_id').head(nr_events)\n",
    "        tmp[\"orig_case_id\"] = tmp['case_id']\n",
    "        tmp['case_id'] = tmp['case_id'].apply(lambda x: \"%s_%s\"%(x, nr_events))\n",
    "        tmp[\"prefix_nr\"] = nr_events\n",
    "        dt_prefixes = pd.concat([dt_prefixes, tmp], axis=0)\n",
    "    dt_prefixes['case_length'] = dt_prefixes['case_length'].apply(lambda x: min(max_length, x))\n",
    "    dt_prefixes = dt_prefixes.sort_values(['case_id', 'prefix_nr'], ascending=[True, True])\n",
    "    return dt_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c0be8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_prefixes = generate_prefix_data(train, min_prefix_length, max_prefix_length)\n",
    "dt_test_prefixes = generate_prefix_data(test, min_prefix_length, max_prefix_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f21860bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['195455_2', '195458_2', '195461_2', '195464_2', '195467_2', '195470_2',\n",
      "       '195473_2', '195485_2', '195491_2', '195497_2',\n",
      "       ...\n",
      "       '200916_2', '200928_2', '200934_2', '200937_2', '200940_2', '200943_2',\n",
      "       '200946_2', '200949_2', '200955_2', '200961_2'],\n",
      "      dtype='object', name='case_id', length=1308)\n"
     ]
    }
   ],
   "source": [
    "import BucketFactory\n",
    "\n",
    "random_state=1234\n",
    "bucketer_args = {'encoding_method': 'last', \n",
    "                 'case_id_col': 'case_id', \n",
    "                 'cat_cols':['activity'], \n",
    "                 'num_cols':[], \n",
    "                 'random_state':random_state}\n",
    "\n",
    "bucket_method = 'prefix'\n",
    "if bucket_method == \"cluster\":\n",
    "    bucketer_args[\"n_clusters\"] = 5\n",
    "bucketer = BucketFactory.get_bucketer(bucket_method, **bucketer_args)\n",
    "bucket_assignments_train = bucketer.fit_predict(dt_train_prefixes)\n",
    "bucket_assignments_test = bucketer.predict(dt_test_prefixes)\n",
    "\n",
    "for bucket_number in bucketer.n_states:\n",
    "    bucket_indexes = dt_train_prefixes.groupby('case_id').first().index\n",
    "    bucket_indexes = bucket_indexes[bucket_assignments_train == bucket_number]\n",
    "    bucket_data = dt_train_prefixes[dt_train_prefixes['case_id'].isin(bucket_indexes)]\n",
    "    bucket_data\n",
    "    def get_label_numeric(data):\n",
    "        y = data.groupby('case_id').first()['remtime']\n",
    "        return y\n",
    "    train_y = get_label_numeric(bucket_data)\n",
    "    \n",
    "bucket_number = 2  \n",
    "bucket_indexes = dt_train_prefixes.groupby('case_id').first().index\n",
    "bucket_indexes = bucket_indexes[bucket_assignments_train == bucket_number]\n",
    "print(bucket_indexes)\n",
    "bucket_data = dt_train_prefixes[dt_train_prefixes['case_id'].isin(bucket_indexes)]\n",
    "\n",
    "def get_label_numeric(data):\n",
    "    y = data.groupby('case_id').first()['remtime']\n",
    "    return y\n",
    "train_y = get_label_numeric(bucket_data)\n",
    "bucket_indexes = dt_test_prefixes.groupby('case_id').first().index\n",
    "bucket_indexes = bucket_indexes[bucket_assignments_test == bucket_number]\n",
    "bucket_data_test = dt_test_prefixes[dt_test_prefixes['case_id'].isin(bucket_indexes)]\n",
    "\n",
    "test_y = get_label_numeric(bucket_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1707be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import EncoderFactory\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "encoding_dict = {\n",
    "    \"laststate\": [\"static\", \"last\"],\n",
    "    \"agg\": [\"static\", \"agg\"],\n",
    "    \"index\": [\"static\", \"index\"],\n",
    "    \"combined\": [\"static\", \"last\", \"agg\"]\n",
    "}\n",
    "\n",
    "methods = encoding_dict['combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1da1442",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_schema = {'case_id_col': 'case_id',\n",
    "'timestamp_col': ['Start_Time', 'End_Time', 'REG_DATE'],\n",
    "'activity_col': 'activity',\n",
    "'label': 'remtime',\n",
    "'negative_outcome': 'deviant',\n",
    "'static_cat_cols': [\"resource\"],\n",
    "'static_num_cols': [\"AMOUNT_REQ\"],\n",
    "'dynamic_cat_cols': [\"activity\", \"resource\"],\n",
    "'dynamic_num_cols': [\"remtime\", 'start_month', 'end_month', 'start_day', 'end_day', 'start_reltime', 'end_reltime'],\n",
    "}\n",
    "\n",
    "feature_combiner = FeatureUnion([(method, EncoderFactory.get_encoder(method, **log_schema)) for method in methods])\n",
    "feature_combiner\n",
    "encoding = feature_combiner.fit_transform(bucket_data, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "254f868d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('encoder',\n",
       "                 FeatureUnion(transformer_list=[('static',\n",
       "                                                 <transformers.StaticTransformer.StaticTransformer object at 0x00000274A190B460>),\n",
       "                                                ('last',\n",
       "                                                 <transformers.LastStateTransformer.LastStateTransformer object at 0x00000274A190B550>),\n",
       "                                                ('agg',\n",
       "                                                 <transformers.AggregateTransformer.AggregateTransformer object at 0x00000274A190B730>)])),\n",
       "                ('cls',\n",
       "                 XGBRegresso...\n",
       "                              feature_types=None, gamma=0, gpu_id=-1,\n",
       "                              grow_policy='depthwise', importance_type=None,\n",
       "                              interaction_constraints='', learning_rate=0.02,\n",
       "                              max_bin=256, max_cat_threshold=64,\n",
       "                              max_cat_to_onehot=4, max_delta_step=0,\n",
       "                              max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "                              missing=nan, monotone_constraints='()',\n",
       "                              n_estimators=1000, n_jobs=2, num_parallel_tree=1,\n",
       "                              predictor='auto', random_state=0, ...))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as XGB\n",
    "\n",
    "model = XGB.XGBRegressor(n_estimators=1000, learning_rate=0.02, n_jobs=2)\n",
    "pipeline = Pipeline([('encoder', feature_combiner), ('cls', model)])\n",
    "pipeline.fit(bucket_data, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a96627e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.72122971071016"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pipeline.predict(bucket_data_test)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "score = mean_absolute_error(test_y, preds)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706d8860",
   "metadata": {},
   "source": [
    "### Task 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b610bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_schema_2 = {'case_id_col': 'case_id',\n",
    "'timestamp_col': ['Start_Time', 'End_Time', 'REG_DATE'],\n",
    "'activity_col': 'activity',\n",
    "'label': 'remtime',\n",
    "'negative_outcome': 'deviant',\n",
    "'static_cat_cols': [\"resource\"],\n",
    "'static_num_cols': [\"AMOUNT_REQ\"],\n",
    "'dynamic_cat_cols': [\"activity\", \"resource\"],\n",
    "'dynamic_num_cols': [\"remtime\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bf022fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_combiner = FeatureUnion([(method, EncoderFactory.get_encoder(method, **log_schema_2)) for method in methods])\n",
    "feature_combiner\n",
    "encoding = feature_combiner.fit_transform(bucket_data, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35e32064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('encoder',\n",
       "                 FeatureUnion(transformer_list=[('static',\n",
       "                                                 <transformers.StaticTransformer.StaticTransformer object at 0x00000274A1916D00>),\n",
       "                                                ('last',\n",
       "                                                 <transformers.LastStateTransformer.LastStateTransformer object at 0x00000274A190B580>),\n",
       "                                                ('agg',\n",
       "                                                 <transformers.AggregateTransformer.AggregateTransformer object at 0x00000274A190B5B0>)])),\n",
       "                ('cls',\n",
       "                 XGBRegresso...\n",
       "                              feature_types=None, gamma=0, gpu_id=-1,\n",
       "                              grow_policy='depthwise', importance_type=None,\n",
       "                              interaction_constraints='', learning_rate=0.02,\n",
       "                              max_bin=256, max_cat_threshold=64,\n",
       "                              max_cat_to_onehot=4, max_delta_step=0,\n",
       "                              max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "                              missing=nan, monotone_constraints='()',\n",
       "                              n_estimators=1000, n_jobs=2, num_parallel_tree=1,\n",
       "                              predictor='auto', random_state=0, ...))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGB.XGBRegressor(n_estimators=1000, learning_rate=0.02, n_jobs=2)\n",
    "pipeline = Pipeline([('encoder', feature_combiner), ('cls', model)])\n",
    "pipeline.fit(bucket_data, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3f1a104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105.31946385672333"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pipeline.predict(bucket_data_test)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "score = mean_absolute_error(test_y, preds)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09851b",
   "metadata": {},
   "source": [
    "There was a minor improvement in the model by removing the extra variables. The extra variables impacted the models ability to predict and were not a necessary addition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
